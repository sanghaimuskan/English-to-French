{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Translation.ipynb",
      "provenance": [],
      "mount_file_id": "1dWSqQyfdpze_AcJ8U6w8XQpMCaDYpXuB",
      "authorship_tag": "ABX9TyPc7Wi+NZSfkJXPJn8bmwah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanghaimuskan/English-to-French/blob/master/Machine_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGi54dEWuHff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8elI3DQ7uLfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8e145a7e-9149-46f5-9f38-99c5c343f942"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgYtdeNp9rT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV7TtfGX-AWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(A, B):\n",
        "    \n",
        "    # you have to set this variable to the true label.\n",
        "    cos = -10\n",
        "    dot = np.dot(A, B)\n",
        "    norma = np.linalg.norm(A)\n",
        "    normb = np.linalg.norm(B)\n",
        "    cos = dot / (norma * normb)\n",
        "\n",
        "    return cos\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpePruMULLKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_tweet(tweet):\n",
        "    \n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "            word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZKpAXrgLlMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dict(file_name):\n",
        "    \n",
        "    my_file = pd.read_csv(file_name, delimiter=' ')\n",
        "    etof = {}  # the english to french dictionary to be returned\n",
        "    for i in range(len(my_file)):\n",
        "        # indexing into the rows.\n",
        "        en = my_file.loc[i][0]\n",
        "        fr = my_file.loc[i][1]\n",
        "        etof[en] = fr\n",
        "\n",
        "    return etof\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw7z7N-__-ze",
        "colab_type": "text"
      },
      "source": [
        "# **The word embeddings data for English and French words**\n",
        "\n",
        "The full dataset for English embeddings is about 3.64 gigabytes, and the French embeddings are about 629 megabytes. so we have taken the subset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52K5FPtWCwTR",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "387b433b-38aa-4eda-bd50-f401b8d7b4d5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c1fee49d-3e68-4b29-a853-ed206e47d7ad\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c1fee49d-3e68-4b29-a853-ed206e47d7ad\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving utf-8''en_embeddings.p to utf-8''en_embeddings.p\n",
            "Saving utf-8''fr_embeddings.p to utf-8''fr_embeddings.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P0NRbaR-nLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "en_embeddings_subset = pickle.load(open(\"utf-8''en_embeddings.p\", \"rb\"))\n",
        "fr_embeddings_subset = pickle.load(open(\"utf-8''fr_embeddings.p\", \"rb\"))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i61CchySHym4",
        "colab_type": "text"
      },
      "source": [
        "# **Loading two dictionaries one for training and other for testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC18F-qCGYhi",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "28bb8528-f48a-4055-a8cf-8854241c006c"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2713fb4a-6696-4880-a3d1-887a5c7ac423\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2713fb4a-6696-4880-a3d1-887a5c7ac423\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving en-fr.test.txt to en-fr.test.txt\n",
            "Saving en-fr.train.txt to en-fr.train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYehvYFyIQ-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c4b7182e-ccf3-44f0-bb22-b831eebeba2a"
      },
      "source": [
        "en_fr_train = get_dict('en-fr.train.txt')\n",
        "print('The length of the English to French training dictionary is', len(en_fr_train))\n",
        "en_fr_test = get_dict('en-fr.test.txt')\n",
        "print('The length of the English to French test dictionary is', len(en_fr_train))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the English to French training dictionary is 5000\n",
            "The length of the English to French test dictionary is 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNGxpAyaOlgg",
        "colab_type": "text"
      },
      "source": [
        "# **Generate embedding and transform matrices**\n",
        "\n",
        "Translating English to French using embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXaGCTNVOjXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    Input:\n",
        "        en_fr: English to French dictionary\n",
        "        french_vecs: French words to their corresponding word embeddings.\n",
        "        english_vecs: English words to their corresponding word embeddings.\n",
        "    Output: \n",
        "        X: a matrix where the columns are the English embeddings.\n",
        "        Y: a matrix where the columns correspong to the French embeddings.\n",
        "        R: the projection matrix that minimizes the F norm ||X R -Y||^2.\n",
        "\"\"\"\n",
        "\n",
        "def get_matrices(en_fr, french_vecs, english_vecs):\n",
        "  # X_l and Y_l are lists of the english and french word embeddings\n",
        "  X_l = list()\n",
        "  Y_l = list()\n",
        "\n",
        "  english_set = english_vecs.keys()\n",
        "  french_set = french_vecs.keys()\n",
        "\n",
        "  for en_word, fr_word in en_fr.items():\n",
        "    if fr_word in french_set and en_word in english_set:\n",
        "\n",
        "      en_vec = english_vecs[en_word]\n",
        "      fr_vec = french_vecs[fr_word]\n",
        "\n",
        "      X_l.append(en_vec)\n",
        "      Y_l.append(fr_vec)\n",
        "\n",
        "  X = np.vstack(X_l)\n",
        "  Y = np.vstack(Y_l)\n",
        "\n",
        "  return X, Y"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV3ROABROab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, Y_train = get_matrices(en_fr_train, fr_embeddings_subset, en_embeddings_subset)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxytnOw9XFG6",
        "colab_type": "text"
      },
      "source": [
        "## **Translations as linear transformation of embeddings**\n",
        "\n",
        "We have to create R (transformation matrix)\n",
        "\n",
        "Find a matrix R that minimizes the loss function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVsXnIlvWk_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(X, Y, R):\n",
        "  m = X.shape[0]\n",
        "  diff = np.dot(X,R) - Y\n",
        "  diff_squared = diff**2\n",
        "\n",
        "  sum_diff = np.sum(diff_squared)\n",
        "  diff_norm = sum_diff/m              #loss\n",
        "\n",
        "  return diff_norm\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bty6ecacZa50",
        "colab_type": "text"
      },
      "source": [
        "## computing the gradient loss in respect to transform matrix R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf8nnZaaZWuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradient (X, Y, R):\n",
        "  m = X.shape[0]\n",
        "\n",
        "  grad = 2/m *np.dot(X.T, (np.dot(X,R)-Y))\n",
        "\n",
        "  return grad"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H83S-CqRaZn2",
        "colab_type": "text"
      },
      "source": [
        "# **Finding an optimal R with gradient descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgFNINtdaWk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def align_embeddings(X, Y, iter = 100, learning_rate = 0.0003):\n",
        "  np.random.seed(120)\n",
        "  R = np.random.rand(X.shape[1],X.shape[1])\n",
        "\n",
        "  for i in range(iter):\n",
        "    gradient = compute_gradient(X, Y, R)\n",
        "\n",
        "    R -= learning_rate*gradient\n",
        "  \n",
        "  return R"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlL-puc-lvHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R_train = align_embeddings(X_train, Y_train, iter=400, learning_rate=0.8)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cf9aNs-nZ41",
        "colab_type": "text"
      },
      "source": [
        "# **K-Nearest Neighbours Algorithm**\n",
        "\n",
        "It takes a vector as input and finds the other vectors in the dataset that are closest to it\n",
        "\n",
        "## **Cosine similarity**\n",
        "Cosine similarity between vectors  𝑢  and  𝑣  calculated as the cosine of the angle between them.\n",
        "\n",
        "Note: Distance and similarity are pretty much opposite things.\n",
        "We can obtain distance metric from cosine similarity, but the cosine similarity can't be used directly as the distance metric.\n",
        "When the cosine similarity increases (towards  1 ), the \"distance\" between the two vectors decreases (towards  0 ).\n",
        "We can define the cosine distance between  𝑢  and  𝑣  as\n",
        "𝑑cos(𝑢,𝑣)=1−cos(𝑢,𝑣)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM2DRlasmlnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nearest_neighbor(v, candidates, k=1):\n",
        "  similarity_l = []\n",
        "\n",
        "  for row in candidates:\n",
        "    cos_similarity = cosine_similarity(v,row)\n",
        "    similarity_l.append(cos_similarity)\n",
        "\n",
        "  sorted_ids = np.argsort(similarity_l)\n",
        "  k_idx = sorted_ids[-k:]\n",
        "\n",
        "  return k_idx"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNFuZPFYp4DG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(X, Y, R):\n",
        "  pred = np.dot(X,R)\n",
        "\n",
        "  num_correct = 0\n",
        "\n",
        "  for i in range(len(pred)):\n",
        "    pred_id = nearest_neighbor(pred[i], Y)\n",
        "\n",
        "    if pred_id == i:\n",
        "      num_correct +=1\n",
        "  \n",
        "  accuracy = num_correct / len(pred)\n",
        "  return accuracy"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkx1JfYQqSgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val, Y_val = get_matrices(en_fr_test, fr_embeddings_subset, en_embeddings_subset)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SVqlq0DtHVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e36170e-0eb5-4266-de7a-46968b15bf3b"
      },
      "source": [
        "acc = test(X_val, Y_val, R_train)  # this might take a minute or two\n",
        "print(f\"accuracy on test set is {acc:.3f}\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on test set is 0.550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKi-pzcotlR0",
        "colab_type": "text"
      },
      "source": [
        "# **LSH and Document search**\n",
        "More efficient version of k-nearest neighbors using locality sensitive hashing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcRZCyS-tJ9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IdPvKKTuno0",
        "colab_type": "text"
      },
      "source": [
        "# **1. Getting the document embeddings**\n",
        "\n",
        "## **Bag of Words document model**\n",
        "\n",
        "Text document sequence\n",
        "example: apple is better than orange and orange is better than apple have different meaning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZs7E3XMt6jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def document_embedding(tweet, en_embeddings):\n",
        "  doc_embedding = np.zeros(300)\n",
        "  processed_doc = process_tweet(tweet)\n",
        "\n",
        "  for word in processed_doc:\n",
        "    doc_embedding+=en_embeddings.get(word,0)\n",
        "  return doc_embedding"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg479Lirwgjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75c34aa3-892c-4602-960a-6b4f61b8b3d8"
      },
      "source": [
        "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
        "tweet_embedding = document_embedding(custom_tweet, en_embeddings_subset)\n",
        "tweet_embedding[-5:]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00268555, -0.15378189, -0.55761719, -0.07216644, -0.32263184])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jl4I638wpkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_document_vecs(all_docs, en_embeddings):\n",
        "  ind2Doc_dict = {}\n",
        "  document_vec_l = []\n",
        "\n",
        "  for i, doc in enumerate(all_docs):\n",
        "    doc_embedding = document_embedding(doc, en_embeddings)\n",
        "\n",
        "    ind2Doc_dict[i] = doc_embedding\n",
        "\n",
        "    document_vec_l.append(doc_embedding)\n",
        "  # convert the list of document vectors into a 2D array (each row is a document vector)\n",
        "  document_vec_matrix = np.vstack(document_vec_l)\n",
        "\n",
        "  return document_vec_matrix, ind2Doc_dict"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e52Jknyq3AGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_tweets = all_negative_tweets + all_positive_tweets\n",
        "document_vecs, ind2Tweet = get_document_vecs(all_tweets, en_embeddings_subset)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc7psUzh4NR2",
        "colab_type": "text"
      },
      "source": [
        "Each plane divides the space to $2$ parts.\n",
        "So $n$ planes divide the space into $2^{n}$ hash buckets.\n",
        "We want to organize 10,000 document vectors into buckets so that every bucket has about $~16$ vectors.\n",
        "For that we need $\\frac{10000}{16}=625$ buckets.\n",
        "We're interested in $n$, number of planes, so that $2^{n}= 625$. Now, we can calculate $n=\\log_{2}625 = 9.29 \\approx 10$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk4RVn4y3tFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The number of planes. We use log2(625) to have ~16 vectors/bucket.\n",
        "N_PLANES = 10\n",
        "# Number of times to repeat the hashing to improve the search.\n",
        "N_UNIVERSES = 25"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G-S8Fbo5lEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_VECS = len(all_tweets)       # This many vectors.\n",
        "N_DIMS = len(ind2Tweet[1])     # Vector dimensionality."
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mC1dUB-4deJ",
        "colab_type": "text"
      },
      "source": [
        "# **Getting a hash number for a vector**\n",
        "\n",
        "### **Hyperlanes in vector space**\n",
        "In $3$-dimensional vector space, the hyperplane is a regular plane. In $2$ dimensional vector space, the hyperplane is a line.\n",
        "Generally, the hyperplane is subspace which has dimension $1$ lower than the original vector space has.\n",
        "A hyperplane is uniquely defined by its normal vector.\n",
        "Normal vector $n$ of the plane $\\pi$ is the vector to which all vectors in the plane $\\pi$ are orthogonal (perpendicular in $3$ dimensional case)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpvHZZYi4BzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "planes_l = [np.random.normal(size=(N_DIMS, N_PLANES))for _ in range(N_UNIVERSES)]"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw1xlikY5XW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hash_value_of_vector(v, planes):\n",
        "  dot_product = np.dot(v, planes)\n",
        "  sign_of_dot = np.sign(dot_product)\n",
        "  h = sign_of_dot>=0\n",
        "\n",
        "  # remove extra un-used dimensions (convert this from a 2D to a 1D array)\n",
        "  h = np.squeeze(h)\n",
        "\n",
        "  hash_value = 0\n",
        "  n_planes = planes.shape[1]\n",
        "\n",
        "  for i in range (n_planes):\n",
        "    hash_value += 2**i*h[i]\n",
        "  # cast hash_value as an integer\n",
        "  hash_value = int(hash_value)\n",
        "\n",
        "  return hash_value"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbGCRKDD8qf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcbe8a95-8326-49e0-ef3a-088afe0adc3e"
      },
      "source": [
        "np.random.seed(0)\n",
        "idx = 0\n",
        "planes = planes_l[idx]  # get one 'universe' of planes to test the function\n",
        "vec = np.random.rand(1, 300)\n",
        "print(f\" The hash value for this vector,\",f\"and the set of planes at index {idx},\",f\"is {hash_value_of_vector(vec, planes)}\")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " The hash value for this vector, and the set of planes at index 0, is 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4KY0-ej9LXw",
        "colab_type": "text"
      },
      "source": [
        "# **Making Hash Table**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRSaE0t58wGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_hash_table(vecs,planes):\n",
        "  num_of_planes = planes.shape[1]\n",
        "  num_buckets = 2**num_of_planes\n",
        "\n",
        "  # create the hash table as a dictionary.\n",
        "  # Keys are integers (0,1,2.. number of buckets)\n",
        "  # Values are empty lists\n",
        "  hash_table = {i:[] for i in range(num_buckets)}\n",
        "  # create the id table as a dictionary.\n",
        "  # Keys are integers (0,1,2... number of buckets)\n",
        "  # Values are empty lists\n",
        "  id_table = {i:[] for i in range(num_buckets)}\n",
        "\n",
        "  for i, v in enumerate(vecs):\n",
        "\n",
        "        # calculate the hash value for the vector\n",
        "        h = hash_value_of_vector(v,planes)\n",
        "        #print(h)\n",
        "        #print('******')\n",
        "        # store the vector into hash_table at key h,\n",
        "        # by appending the vector v to the list at key h\n",
        "        hash_table[h].append(v)\n",
        "\n",
        "        # store the vector's index 'i' (each document is given a unique integer 0,1,2...)\n",
        "        # the key is the h, and the 'i' is appended to the list at key h\n",
        "        id_table[h].append(i)\n",
        "  return hash_table, id_table"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiE-g1Nm-qnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b62a7139-0c94-4814-f078-f1ac97f9b1ed"
      },
      "source": [
        "np.random.seed(0)\n",
        "planes = planes_l[0]  # get one 'universe' of planes to test the function\n",
        "vec = np.random.rand(1, 300)\n",
        "tmp_hash_table, tmp_id_table = make_hash_table(document_vecs, planes)\n",
        "\n",
        "print(f\"The hash table at key 0 has {len(tmp_hash_table[0])} document vectors\")\n",
        "print(f\"The id table at key 0 has {len(tmp_id_table[0])}\")\n",
        "print(f\"The first 5 document indices stored at key 0 of are {tmp_id_table[0][0:5]}\")"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The hash table at key 0 has 3 document vectors\n",
            "The id table at key 0 has 3\n",
            "The first 5 document indices stored at key 0 of are [8276, 8281, 8282]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWk_dfBZ-wE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "5e38fca7-e0d4-4f88-cc0e-02932c367940"
      },
      "source": [
        "# Creating the hashtables\n",
        "hash_tables = []\n",
        "id_tables = []\n",
        "for universe_id in range(N_UNIVERSES):  # there are 25 hashes\n",
        "    print('working on hash universe #:', universe_id)\n",
        "    planes = planes_l[universe_id]\n",
        "    hash_table, id_table = make_hash_table(document_vecs, planes)\n",
        "    hash_tables.append(hash_table)\n",
        "    id_tables.append(id_table)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "working on hash universe #: 0\n",
            "working on hash universe #: 1\n",
            "working on hash universe #: 2\n",
            "working on hash universe #: 3\n",
            "working on hash universe #: 4\n",
            "working on hash universe #: 5\n",
            "working on hash universe #: 6\n",
            "working on hash universe #: 7\n",
            "working on hash universe #: 8\n",
            "working on hash universe #: 9\n",
            "working on hash universe #: 10\n",
            "working on hash universe #: 11\n",
            "working on hash universe #: 12\n",
            "working on hash universe #: 13\n",
            "working on hash universe #: 14\n",
            "working on hash universe #: 15\n",
            "working on hash universe #: 16\n",
            "working on hash universe #: 17\n",
            "working on hash universe #: 18\n",
            "working on hash universe #: 19\n",
            "working on hash universe #: 20\n",
            "working on hash universe #: 21\n",
            "working on hash universe #: 22\n",
            "working on hash universe #: 23\n",
            "working on hash universe #: 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfqs7pSe_f-C",
        "colab_type": "text"
      },
      "source": [
        "# **Approximate K-NN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngvGM9Jj_VNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def aprx_knn(doc_id, v, planes_l, k=1, num_universes_to_use = N_UNIVERSES):\n",
        "    \n",
        "    \n",
        "\n",
        "    # Vectors that will be checked as possible nearest neighbor\n",
        "    vecs_to_consider_l = list()\n",
        "\n",
        "    # list of document IDs\n",
        "    ids_to_consider_l = list()\n",
        "\n",
        "    # create a set for ids to consider, for faster checking if a document ID already exists in the set\n",
        "    ids_to_consider_set = set()\n",
        "\n",
        "    # loop through the universes of planes\n",
        "    for universe_id in range(num_universes_to_use):\n",
        "\n",
        "        # get the set of planes from the planes_l list, for this particular universe_id\n",
        "        planes = planes_l[universe_id]\n",
        "\n",
        "        # get the hash value of the vector for this set of planes\n",
        "        hash_value = hash_value_of_vector(v, planes)\n",
        "\n",
        "        # get the hash table for this particular universe_id\n",
        "        hash_table = hash_tables[universe_id]\n",
        "\n",
        "        # get the list of document vectors for this hash table, where the key is the hash_value\n",
        "        document_vectors_l = hash_table[hash_value]\n",
        "\n",
        "        # get the id_table for this particular universe_id\n",
        "        id_table = id_tables[universe_id]\n",
        "\n",
        "        # get the subset of documents to consider as nearest neighbors from this id_table dictionary\n",
        "        new_ids_to_consider = id_table[hash_value]\n",
        "\n",
        "        # remove the id of the document that we're searching\n",
        "        if doc_id in new_ids_to_consider:\n",
        "            new_ids_to_consider.remove(doc_id)\n",
        "            print(f\"removed doc_id {doc_id} of input vector from new_ids_to_search\")\n",
        "\n",
        "        # loop through the subset of document vectors to consider\n",
        "        for i, new_id in enumerate(new_ids_to_consider):\n",
        "\n",
        "            # if the document ID is not yet in the set ids_to_consider...\n",
        "            if new_id not in ids_to_consider_set:\n",
        "                # access document_vectors_l list at index i to get the embedding\n",
        "                # then append it to the list of vectors to consider as possible nearest neighbors\n",
        "                document_vector_at_i = document_vectors_l[i]\n",
        "                \n",
        "\n",
        "                # append the new_id (the index for the document) to the list of ids to consider\n",
        "                vecs_to_consider_l.append(document_vector_at_i)\n",
        "                ids_to_consider_l.append(new_id)\n",
        "                # also add the new_id to the set of ids to consider\n",
        "                # (use this to check if new_id is not already in the IDs to consider)\n",
        "                ids_to_consider_set.add(new_id)\n",
        "       \n",
        "\n",
        "    # Now run k-NN on the smaller set of vecs-to-consider.\n",
        "    print(\"Fast considering %d vecs\" % len(vecs_to_consider_l))\n",
        "\n",
        "    # convert the vecs to consider set to a list, then to a numpy array\n",
        "    vecs_to_consider_arr = np.array(vecs_to_consider_l)\n",
        "\n",
        "    # call nearest neighbors on the reduced list of candidate vectors\n",
        "    nearest_neighbor_idx_l = nearest_neighbor(v, vecs_to_consider_arr, k=k)\n",
        "\n",
        "    # Use the nearest neighbor index list as indices into the ids to consider\n",
        "    # create a list of nearest neighbors by the document ids\n",
        "    nearest_neighbor_ids = [ids_to_consider_l[idx]\n",
        "                            for idx in nearest_neighbor_idx_l]\n",
        "\n",
        "    return nearest_neighbor_ids"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta6DknlMAQAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#document_vecs, ind2Tweet\n",
        "doc_id = 0\n",
        "doc_to_search = all_tweets[doc_id]\n",
        "vec_to_search = document_vecs[doc_id]"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu4binuAAUmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "411b021b-bb36-4d51-9e75-4fa0865a276a"
      },
      "source": [
        "nearest_neighbor_ids = aprx_knn(doc_id, vec_to_search, planes_l, k=3, num_universes_to_use=5)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "removed doc_id 0 of input vector from new_ids_to_search\n",
            "removed doc_id 0 of input vector from new_ids_to_search\n",
            "removed doc_id 0 of input vector from new_ids_to_search\n",
            "removed doc_id 0 of input vector from new_ids_to_search\n",
            "removed doc_id 0 of input vector from new_ids_to_search\n",
            "Fast considering 1355 vecs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOIAJrmeAYEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "3e05db9e-6455-4b57-ec7b-9cdf2579bf5f"
      },
      "source": [
        "print(f\"Nearest neighbors for document {doc_id}\")\n",
        "print(f\"Document contents: {doc_to_search}\")\n",
        "print(\"\")\n",
        "\n",
        "for neighbor_id in nearest_neighbor_ids:\n",
        "    print(f\"Nearest neighbor at document id {neighbor_id}\")\n",
        "    print(f\"document contents: {all_tweets[neighbor_id]}\")"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nearest neighbors for document 0\n",
            "Document contents: hopeless for tmr :(\n",
            "\n",
            "Nearest neighbor at document id 2990\n",
            "document contents: I'm starving :(\n",
            "Nearest neighbor at document id 3030\n",
            "document contents: 11:11 a boyfriend :(\n",
            "Nearest neighbor at document id 5727\n",
            "document contents: kill :) me :) http://t.co/5kon9Txmf6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NUBeDdzA7NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}